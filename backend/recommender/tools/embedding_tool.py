from langchain.tools import BaseTool
from typing import Optional, Type
from pydantic import BaseModel, Field
import os
import torch
import numpy as np
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âš™ï¸ åˆå§‹åŒ–æ¨¡å‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMBED_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
SENTIMENT_MODEL_NAME = "uer/roberta-base-finetuned-dianping-chinese"

# æ¨¡å‹å¿«å–è³‡æ–™å¤¾ï¼ˆä¸æœƒä¸Šå‚³ GitHubï¼‰
MODEL_DIR = os.path.join(os.path.dirname(__file__), "..", "models")

def load_embedder():
    local_path = os.path.join(MODEL_DIR, "MiniLM-L12-v2")
    try:
        # å„ªå…ˆè®€å–æœ¬åœ°å¿«å–
        if os.path.exists(local_path):
            return SentenceTransformer(local_path)
        # æ²’æœ‰å°±ä¸‹è¼‰ä¸€æ¬¡
        return SentenceTransformer(EMBED_MODEL_NAME, cache_folder=MODEL_DIR)
    except Exception as e:
        print("[WARN] Embedding æ¨¡å‹ä¸‹è¼‰å¤±æ•—ï¼Œæ”¹ç”¨ fallback (è©å‘é‡å¤±æ•ˆ)")
        return None  # ä¹‹å¾Œåˆ†ææ™‚æœƒç”¨ fallback æ’åº

def load_sentiment_analyzer():
    local_path = os.path.join(MODEL_DIR, "dianping-sentiment")
    # ğŸ–¥ï¸ GPU or CPU æ§åˆ¶åœ¨é€™è£¡ï¼
    device = 0 if torch.cuda.is_available() else -1
    try:
        if os.path.exists(local_path):
            return pipeline("sentiment-analysis", model=local_path, device=device)
        
        # âœ… ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºçš„æ–¹å¼å‚³é cache_dir
        # transformers 4.x ç‰ˆæœ¬éœ€è¦é€é model_kwargs æˆ–ç›´æ¥åœ¨ from_pretrained æ™‚è¨­å®š
        return pipeline(
            "sentiment-analysis", 
            model=SENTIMENT_MODEL_NAME,
            device=device,
            model_kwargs={"cache_dir": MODEL_DIR}
        )
    except Exception as e:
        print("[WARN] Sentiment æ¨¡å‹ä¸‹è¼‰å¤±æ•—ï¼Œæ”¹ç”¨ fallback (ä¸åšæƒ…ç·’åˆ†æ)")
        print(f"[WARN] éŒ¯èª¤è©³æƒ…ï¼š{e}")
        return None

embedder = load_embedder()
sentiment_analyzer = load_sentiment_analyzer()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§© ç”¢ç”Ÿè©•è«–å‘é‡ä¸¦å„²å­˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def encode_reviews_to_vector(reviews, save_path=None):
    """å°‡è©•è«–æ–‡å­—è½‰æˆ embedding ä¸¦å¿«å–"""
    texts = [r.get("text", "") for r in reviews if r.get("text")]
    if not texts:
        return None

    embeddings = embedder.encode(texts, convert_to_tensor=True, show_progress_bar=False)

    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        torch.save(embeddings, save_path)
    return embeddings


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§® åˆ†æè©•è«–å…§å®¹èˆ‡åå¥½èªæ„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_reviews(reviews, preferences):
    """æ ¹æ“šåå¥½èªæ„åˆ†æé¤å»³è©•è«–åŒ¹é…ç¨‹åº¦èˆ‡æ­£é¢ç‡"""
    if not reviews:
        return {
            "summary": "ç„¡è©•è«–è³‡æ–™",
            "match_score": 0.0,
            "positive_rate": 0.0,
        }

    review_texts = [r.get("text", "") for r in reviews if r.get("text")]
    
    # âœ… åŠ å…¥æª¢æŸ¥ï¼šå¦‚æœæ²’æœ‰ embedderï¼Œä½¿ç”¨ fallback
    if not embedder:
        print("[WARN] Embedder æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ fallback åˆ†æ")
        return {
            "summary": " / ".join(review_texts[:3]),
            "match_score": 0.5,  # çµ¦äºˆä¸­ç­‰åˆ†æ•¸
            "positive_rate": 0.5,
        }
    
    review_emb = embedder.encode(review_texts, convert_to_tensor=True, show_progress_bar=False)

    # å°åå¥½é€²è¡Œ embedding
    pref_text = "ï¼Œ".join(preferences) if preferences else "ä¸€èˆ¬ç”¨é¤é«”é©—"
    pref_emb = embedder.encode([pref_text], convert_to_tensor=True)

    # èªæ„ç›¸ä¼¼åº¦
    sim_scores = util.cos_sim(pref_emb, review_emb).cpu().numpy().flatten()
    match_score = float(np.mean(sim_scores)) if len(sim_scores) > 0 else 0.0

    # è¨ˆç®—æ­£å‘è©•è«–æ¯”ä¾‹
    if sentiment_analyzer:
        try:
            sentiments = sentiment_analyzer(review_texts[:50])  # é™åˆ¶æœ€å¤š 50 å‰‡åŠ é€Ÿ
            positive_count = sum(1 for s in sentiments if s["label"].lower().startswith("pos"))
            positive_rate = positive_count / len(sentiments) if sentiments else 0.0
        except Exception as e:
            print(f"[WARN] Sentiment åˆ†æå¤±æ•—ï¼š{e}")
            positive_rate = 0.5  # fallback
    else:
        positive_rate = 0.5  # ç„¡ sentiment analyzer æ™‚çµ¦äºˆä¸­ç­‰åˆ†æ•¸

    # æ‘˜è¦ï¼šå–æœ€ç›¸é—œä¸‰å¥è©•è«–
    top_idx = np.argsort(sim_scores)[-10:][::-1]
    top_reviews = [review_texts[i] for i in top_idx]
    summary = " / ".join(top_reviews)

    return {
        "summary": summary,
        "match_score": round(match_score, 3),
        "positive_rate": round(positive_rate, 3),
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§  LangChain Tool åŒ…è£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class EmbeddingAnalysisInput(BaseModel):
    reviews: list = Field(..., description="è©•è«–åˆ—è¡¨ï¼Œæ¯é …åŒ…å« 'text'")
    preferences: Optional[list[str]] = Field(default=[], description="ä½¿ç”¨è€…åå¥½ï¼Œå¦‚ ['å®‰éœ', 'æ°£æ°›å¥½']")


class EmbeddingAnalysisTool(BaseTool):
    name: str = "embedding_analysis_tool"
    description: str = "åˆ†æè©•è«–èˆ‡ä½¿ç”¨è€…åå¥½çš„èªæ„ç›¸ä¼¼åº¦èˆ‡æƒ…æ„Ÿå‚¾å‘"
    args_schema: Type[BaseModel] = EmbeddingAnalysisInput

    def _run(self, reviews: list, preferences: Optional[list[str]] = None):
        result = analyze_reviews(reviews, preferences or [])
        return result

    async def _arun(self, **kwargs):
        raise NotImplementedError("æ­¤å·¥å…·ä¸æ”¯æ´ async æ¨¡å¼")